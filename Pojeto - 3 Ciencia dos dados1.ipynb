{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import cv2\n",
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = pd.read_csv('USvideos.csv').loc[:, [\"trending_date\",\"title\",\"channel_title\",\"category_id\",\"publish_time\",\"tags\",\"views\",\"likes\",\"dislikes\",\"comment_count\",\"thumbnail_link\",\"comments_disabled\",\"ratings_disabled\",\"video_error_or_removed\",\"description\"]]\n",
    "\n",
    "lnks = ndata.loc[:, [\"title\",\"thumbnail_link\", \"views\"]].drop_duplicates(subset = \"thumbnail_link\", keep = \"last\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# z = []\n",
    "# c = 0\n",
    "\n",
    "# for i in lnks[\"thumbnail_link\"]:\n",
    "    \n",
    "#     if c <= 5000:\n",
    "        \n",
    "#         try:\n",
    "#             req.urlretrieve(i, \"{}.jpg\".format(c))\n",
    "#             x.append(lnks[\"views\"][lnks.thumbnail_link[lnks.thumbnail_link == i].index.tolist()[0]])\n",
    "#             z.append(lnks[\"title\"][lnks.thumbnail_link[lnks.thumbnail_link == i].index.tolist()[0]])\n",
    "#             c += 1\n",
    "            \n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#     else:\n",
    "#         break\n",
    "    \n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "# vectx = vectorizer.fit_transform(z)\n",
    "# vectx = vectx.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('z.txt', 'w') as f:\n",
    "#     for item in vectx:\n",
    "#         for i in item:\n",
    "#             f.write(str(i) + \"\\n\")\n",
    "\n",
    "# with open('x.txt', 'w') as f:\n",
    "#     for item in x:\n",
    "#         f.write(str(item) + \"\\n\")\n",
    "        \n",
    "# len(vectx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faixa 1 = 0, 100652.364\n",
    "# faixa 2 = 100652.364, 504283.8\n",
    "# faixa 3 = 504283.8, 1008510.6\n",
    "# faixa 4 = 1008510.6, 5127377.4\n",
    "# faixa 5 = 5127377.4, 50169650.2\n",
    "# faixa 6 = 50169650.2, 225211923.0\n",
    "\n",
    "views_y = []\n",
    "\n",
    "with open('x.txt', 'r') as f:\n",
    "    for item in f:\n",
    "        if int(item[:-1]) < 100000:\n",
    "            views_y.append(1)\n",
    "        \n",
    "        if int(item[:-1]) > 100000 and int(item[:-1]) < 500000:\n",
    "            views_y.append(2)\n",
    "        \n",
    "        if int(item[:-1]) > 500000 and int(item[:-1]) < 1000000:\n",
    "            views_y.append(3)\n",
    "        \n",
    "        if int(item[:-1]) > 1000000 and int(item[:-1]) < 5000000:\n",
    "            views_y.append(4)\n",
    "        \n",
    "        if int(item[:-1]) > 5000000:\n",
    "            views_y.append(5)\n",
    "\n",
    "len(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "vect = []\n",
    "l = []\n",
    "\n",
    "with open('z.txt', 'r') as f:\n",
    "    for item in f:\n",
    "        \n",
    "        if c < 9115:\n",
    "            l.append(int(item[:-1]))\n",
    "            \n",
    "        else:\n",
    "            vect.append(l)\n",
    "            l = []\n",
    "            c = 0\n",
    "            \n",
    "        c += 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-af02dc0113d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlista_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_crop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mlista_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "lista_x = []\n",
    "\n",
    "for i in range(5001):\n",
    "    im = cv2.imread('{}.jpg'.format(i))\n",
    "    img_crop = cv2.pyrDown(im)\n",
    "    img_crop = cv2.pyrDown(img_crop)\n",
    "    img_crop = cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB)\n",
    "    lista_x.append(img_crop.flatten())\n",
    "    \n",
    "lista_x = np.concatenate((lista_x, vect),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuff = list(zip(lista_x, views_y))\n",
    "\n",
    "random.shuffle(shuff)\n",
    "\n",
    "lista_x, views_y = zip(*shuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = round(len(lista_x)*0.95)\n",
    "lista_x_train, lista_x_test = lista_x[:index], lista_x[index:]\n",
    "len(lista_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_y\n",
    "index_ = round(len(views_y)*0.95)\n",
    "views_y_train, views_y_test = views_y[:index_], views_y[index_:]\n",
    "len(views_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss = \"hinge\", penalty = \"l2\", max_iter = 100)\n",
    "clf.fit(lista_x_train, views_y_train)\n",
    "y_pred = clf.predict(lista_x_test)\n",
    "print('Acurácia: {}'.format(accuracy_score(views_y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100, max_depth = 2,random_state = 0)\n",
    "clf.fit(lista_x_train, views_y_train)\n",
    "y_pred = clf.predict(lista_x_test)\n",
    "print('Acurácia: {}'.format(accuracy_score(views_y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "rbf_feature = RBFSampler(gamma = 1, random_state = 1)\n",
    "X_features = rbf_feature.fit_transform(lista_x_train)\n",
    "clf = SGDClassifier(max_iter = 100)\n",
    "clf.fit(lista_x_train, views_y_train) \n",
    "y_pred = clf.predict(lista_x_test)\n",
    "print('Acurácia: {}'.format(accuracy_score(views_y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Objetivo do projeto é indentificar em qual faixa de views (0 - 100 mil, ...) um vídeo vai estar, dada somente sua tumbnail como entrada. Para isso, foi baixado um dataset contendo diversas variáveis como \"likes\", \"dislikes\", ..., etc. Cada coluna diz respeito a algum feature que o youtube utiliza como caracteristicas do video, como pode ser visto abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o nosso projeto consta somente com a imagem, cortamos o dataset em um com apenas o link das tumbnails e o número de views do vídeo. É importante dizer que os dados foram atualizados todos os dias durante o tempo, o que significa que existem videos iguais em diferentes dias, e por isso utilizamos do ferramental pandas para tirar todas as tumbnails iguais. Por conta disso, em alguns casos o número de views é diferente para o mesmo link (vídeo), optamos por considerar a ultima vez q o dataset foi atualizado, ou seja, o maior número de views de um vídeo igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lnks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o banco de dados pronto para ser utilizado, o próximo passo seria baixar as fotos para o computador, para otimizar o tempo na hora de trabalhar no modelo. Como muitas tumbnails não existem (vídeo removido, não existe mais foto), foi utilizado o try, e logo depois adicionado o número de views a uma lista chamada \"x\" (não tem relação com o modelo, o nome \"x\" é apenas representativo). \n",
    "\n",
    "    import urllib.request as req\n",
    "\n",
    "    x = []\n",
    "    c = 0\n",
    "\n",
    "    for i in lnks[\"thumbnail_link\"]:\n",
    "\n",
    "        if c <= 5000:\n",
    "\n",
    "            try:\n",
    "                req.urlretrieve(i, \"{}.jpg\".format(c))\n",
    "                x.append(lnks[\"views\"][lnks.thumbnail_link[lnks.thumbnail_link == i].index.tolist()[0]])\n",
    "                c += 1\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, como nosso modelo adota o uso de imagens para análise do numero de views, não é possível plotar histogramas ou boxplots, o que nos leva a descartar tal tipo de análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi salvo os views da lista \"x\" em um arquivo para nao ter de rodar novamente o código acima, o que acabaria baixando novamente as fotos.\n",
    "\n",
    "    with open('x.txt', 'w') as f:\n",
    "        for item in x:\n",
    "            f.write(str(item) + \"\\n\")\n",
    "\n",
    "Com o y pronto (número de views) e dividido em faixas, o próximo passo seria achar algum meio de transformar as imagens baixadas em um array que representaria o x do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso foi utilizado o cv2 para ler e converter as imagens em array, e prontas para serem utilizadas no modelo.\n",
    "\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "\n",
    "    imagens_x = []\n",
    "\n",
    "    for i in range(5001):\n",
    "        im = cv2.imread('{}.jpg'.format(i))\n",
    "        img_crop = cv2.pyrDown(im)\n",
    "        img_crop = cv2.pyrDown(img_crop)\n",
    "        img_crop = cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB)\n",
    "        imagens_x.append(img_crop.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de testar os modelos, algumas alterações foram feitas nas listas x e y, como por exemplo o shuffle. Dividimos 95% das duas listas para treino, e o resto para classificação.\n",
    "Ao entrar no site do sikit em \"Flow Chart\", alguns modelos foram testados seguindo a sugestão do mesmo.\n",
    "Como o máximo de acurácia foi 33%, escolhemos entender melhor o que as imagens nos diziam, portanto, o proximo passo para melhorar a acurácia é criar meios de análise da imagem, para ajudar o classificador a melhorar os acertos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
